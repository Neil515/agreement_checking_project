# risk_analyzer.pyï¼ˆæ•´åˆ GPT åˆ†æï¼‰
import os
import json
import re
import openai
from dotenv import load_dotenv

# è¼‰å…¥ .env ç’°å¢ƒè®Šæ•¸
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# æç¤ºèªè®€å–ï¼ˆä¸­è‹±æ–‡ï¼‰
def load_prompt(lang):
    prompt_path = f"prompts/prompt_template_{lang}.txt"
    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read()

# åˆ¤æ–·æ˜¯å¦ç‚ºä¸Šä¸‹æ–‡å¥å­ï¼ˆéæ¢æ¬¾é¡ï¼‰
def is_contextual_sentence(sentence: str) -> bool:
    if sentence.isupper():
        return True
    if re.match(r'^\s*(Definitions|Section|Contact|Welcome|This agreement)', sentence, re.I):
        return True
    if len(sentence) < 15 and not re.search(r'\b(is|are|shall|must|will)\b', sentence):
        return True
    if re.search(r'visit our website|for more info', sentence, re.I):
        return True
    return False

# åˆ¤æ–·æ˜¯å¦ç¼ºä¹é«˜é¢¨éšªé—œéµçµ„åˆï¼ˆä¸­è‹±æ–‡åˆ†æµï¼‰
KEYWORD_COMBINATIONS_EN = [
    ["terminate", "without"],
    ["release", "liability"],
    ["solely", "liable"],
    ["not", "responsible"],
    ["grant", "permission"],
    ["exclusive", "rights"],
    ["without", "consent"],
    ["agree", "indemnify"]
]

KEYWORD_COMBINATIONS_ZH = [
    ["çµ‚æ­¢", "å¥‘ç´„"],
    ["é•ç´„", "é‡‘"],
    ["è§£é™¤", "åˆç´„"],
    ["è³ å„Ÿ", "è²¬ä»»"],
    ["ä¸å†", "è¿½å„Ÿ"]
]

def lacks_high_risk_combinations(sentence: str, lang: str) -> bool:
    sentence_lower = sentence.lower()
    keyword_combos = KEYWORD_COMBINATIONS_ZH if lang == "zh" else KEYWORD_COMBINATIONS_EN
    for combo in keyword_combos:
        if all(word in sentence_lower for word in combo):
            return False
    return True

# å‘¼å« OpenAI åˆ†ææ¢æ–‡
def gpt_analyze(clause, lang):
    prompt = load_prompt(lang)
    full_prompt = f"{prompt}\n\næ¢æ–‡ï¼š{clause}"

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ¢æ¬¾é¢¨éšªåˆ†æåŠ©æ‰‹"},
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.3,
            timeout=10
        )
        text = response['choices'][0]['message']['content'].strip()
        # è‡ªå‹•å»é™¤åŒ…è£¹çš„ç¨‹å¼ç¢¼å€å¡Šç¬¦è™Ÿï¼ˆå¼·åŒ–ï¼‰
        if text.startswith("```"):
            text = re.sub(r"^```(?:json)?\s*", "", text)
            text = re.sub(r"\s*```$", "", text)

        print("ğŸ“… GPT å›å‚³å…§å®¹ï¼š", text)  # é™¤éŒ¯ç”¨
        result = json.loads(text)
        result["clause"] = clause  # ç¢ºä¿åŸæ–‡ä¿ç•™

        # å¥—ç”¨ highlight æ¨™è¨˜é‚è¼¯
        if result.get("risk_level") in ["é«˜", "é ˆæ³¨æ„"]:
            result["risk_level"] = "é ˆæ³¨æ„"
            result["highlight"] = True
        else:
            result["risk_level"] = "ä¸€èˆ¬è³‡è¨Š"
            result["highlight"] = False

        return result
    except Exception as e:
        print(f"âš ï¸ GPT API åˆ†æå¤±æ•—ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ï¼š{e}")
        return mock_analyze(clause, lang)

# æ¨¡æ“¬æ¨¡å¼ï¼ˆå‚™ç”¨ï¼‰
def mock_analyze(clause, lang):
    return {
        "clause": clause,
        "risk_level": "é ˆæ³¨æ„",
        "type": "å·²åŒæ„æ¬Š",
        "reason": "æ¨¡æ“¬é¢¨éšªçµæœï¼ˆæœªé€£æ¥ GPTï¼‰",
        "highlight": True
    }

# å°å¤–å‡½å¼
def analyze_clause(clause, lang):
    if is_contextual_sentence(clause):
        return {
            "clause": clause,
            "risk_level": "ä¸€èˆ¬è³‡è¨Š",
            "type": "Contextual",
            "reason": "Contextual sentence (e.g., definition, heading, or background info)",
            "highlight": False
        }

    if lacks_high_risk_combinations(clause, lang):
        return {
            "clause": clause,
            "risk_level": "ä¸€èˆ¬è³‡è¨Š",
            "type": "Informative",
            "reason": "No high-risk keyword combinations detected",
            "highlight": False
        }

    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return gpt_analyze(clause, lang)
    else:
        return mock_analyze(clause, lang)
