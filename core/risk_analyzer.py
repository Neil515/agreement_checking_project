# risk_analyzer.pyï¼ˆæ•´åˆ GPT åˆ†æï¼‰
import os
import json
import openai
from dotenv import load_dotenv

# è¼‰å…¥ .env ç’°å¢ƒè®Šæ•¸
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# æç¤ºèªè®€å–ï¼ˆä¸­è‹±æ–‡ï¼‰
def load_prompt(lang):
    prompt_path = f"prompts/prompt_template_{lang}.txt"
    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read()

# å‘¼å« OpenAI åˆ†ææ¢æ–‡
def gpt_analyze(clause, lang):
    prompt = load_prompt(lang)
    full_prompt = f"{prompt}\n\næ¢æ–‡ï¼š{clause}"

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ¢æ¬¾é¢¨éšªåˆ†æåŠ©æ‰‹"},
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.3,
            timeout=10
        )
        text = response['choices'][0]['message']['content']
        print("ğŸ“¥ GPT å›å‚³å…§å®¹ï¼š", text)  # é™¤éŒ¯ç”¨
        result = json.loads(text)
        result["clause"] = clause  # ç¢ºä¿åŸæ–‡ä¿ç•™
        return result
    except Exception as e:
        print(f"âš ï¸ GPT API åˆ†æå¤±æ•—ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ï¼š{e}")
        return mock_analyze(clause, lang)

# æ¨¡æ“¬æ¨¡å¼ï¼ˆå‚™ç”¨ï¼‰
def mock_analyze(clause, lang):
    return {
        "clause": clause,
        "risk_level": "ä¸­",
        "type": "å·²åŒæ„æ¬Š",
        "reason": "æ¨¡æ“¬é¢¨éšªçµæœï¼ˆæœªé€£æ¥ GPTï¼‰"
    }

# å°å¤–å‡½å¼

def analyze_clause(clause, lang):
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return gpt_analyze(clause, lang)
    else:
        return mock_analyze(clause, lang)
